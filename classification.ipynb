{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1a3e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import gdown # GoogleDrive Downloader\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "!pip install landingai\n",
    "from landingai.pipeline.frameset import Frame\n",
    "from landingai.predict import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8503691",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NameError\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mgdown\u001b[49m\u001b[38;5;241m.\u001b[39mdownload(url, zip_fp, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, fuzzy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gdown' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     gdown\u001b[38;5;241m.\u001b[39mdownload(url, zip_fp, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, fuzzy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDownload Failed: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43me\u001b[49m)\n\u001b[1;32m     14\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(zip_fp)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NameError\") to str"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "url = 'YOUR_DRIVE_LINK_WHERE_DATA_FOLDER_IS-UPLOADED'\n",
    "data_fp = os.path.join(os.getcwd(), 'data')\n",
    "try: \n",
    "    os.makedirs(data_fp, exist_ok=False)\n",
    "except OSError:\n",
    "    os.system(\"rm -rf \" + data_fp)\n",
    "    os.makedirs(data_fp, exist_ok=False)\n",
    "zip_fp = os.path.join(os.getcwd(), 'data', 'CMPT340_Project.zip')\n",
    "try:\n",
    "    gdown.download(url, zip_fp, quiet=False, fuzzy=True)\n",
    "except Exception as e:\n",
    "    print(\"Download Failed: \" +e)\n",
    "    os.remove(zip_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28445a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompress the ZIP\n",
    "with zipfile.ZipFile(zip_fp, 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.path.join(os.getcwd(), 'data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f45ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set creation completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/_p67rfks2tn1n4g8bh_30fdh0000gn/T/ipykernel_26228/1670027498.py:36: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  benign_validation_files = random.sample(set(benign_files) - classification_files, min(benign_validation_size, len(benign_files)))\n",
      "/var/folders/pk/_p67rfks2tn1n4g8bh_30fdh0000gn/T/ipykernel_26228/1670027498.py:37: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  malignant_validation_files = random.sample(set(malignant_files) - classification_files, min(malignant_validation_size, len(malignant_files)))\n",
      "/var/folders/pk/_p67rfks2tn1n4g8bh_30fdh0000gn/T/ipykernel_26228/1670027498.py:38: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  normal_validation_files = random.sample(set(normal_files) - classification_files, min(normal_validation_size, len(normal_files)))\n"
     ]
    }
   ],
   "source": [
    "# Set the paths\n",
    "project_folder = os.path.join(os.getcwd(), 'data', 'CMPT340_Project')\n",
    "dataset_folder = os.path.join(project_folder, 'BreastCancerDataset')\n",
    "classification_folder = os.path.join(project_folder, 'dataset-classification')\n",
    "\n",
    "# Validation set sizes\n",
    "benign_validation_size = 10\n",
    "malignant_validation_size = 15\n",
    "normal_validation_size = 5\n",
    "\n",
    "# Function to copy files from source to destination\n",
    "def copy_files(source_folder, destination_folder, file_list):\n",
    "    for file_name in file_list:\n",
    "        source_path = os.path.join(source_folder, file_name)\n",
    "        destination_path = os.path.join(destination_folder, file_name)\n",
    "        shutil.copy(source_path, destination_path)\n",
    "\n",
    "# Create the validation set folders\n",
    "validation_folder = os.path.join(classification_folder, 'validation')\n",
    "\n",
    "# Remove the existing validation folder if it exists\n",
    "if os.path.exists(validation_folder):\n",
    "    shutil.rmtree(validation_folder)\n",
    "\n",
    "os.makedirs(validation_folder, exist_ok=True)\n",
    "\n",
    "# Get the list of files in each class\n",
    "benign_files = [file for file in os.listdir(os.path.join(dataset_folder, 'benign')) if '_mask' not in file]\n",
    "malignant_files = [file for file in os.listdir(os.path.join(dataset_folder, 'malignant')) if '_mask' not in file]\n",
    "normal_files = [file for file in os.listdir(os.path.join(dataset_folder, 'normal')) if '_mask' not in file]\n",
    "\n",
    "# Get the list of files in the classification folder\n",
    "classification_files = set(os.listdir(classification_folder))\n",
    "\n",
    "# Randomly select validation files\n",
    "benign_validation_files = random.sample(set(benign_files) - classification_files, min(benign_validation_size, len(benign_files)))\n",
    "malignant_validation_files = random.sample(set(malignant_files) - classification_files, min(malignant_validation_size, len(malignant_files)))\n",
    "normal_validation_files = random.sample(set(normal_files) - classification_files, min(normal_validation_size, len(normal_files)))\n",
    "\n",
    "# Copy files to the validation set folders\n",
    "copy_files(os.path.join(dataset_folder, 'benign'), validation_folder, benign_validation_files)\n",
    "copy_files(os.path.join(dataset_folder, 'malignant'), validation_folder, malignant_validation_files)\n",
    "copy_files(os.path.join(dataset_folder, 'normal'), validation_folder, normal_validation_files)\n",
    "\n",
    "# Print a message indicating that the validation set creation was successful\n",
    "print(\"Validation set creation completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d9173",
   "metadata": {},
   "source": [
    "# Run inference on the validation set with the trained model deployed on LandingAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install landingai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ac975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sanyamsingh/Desktop/Courses/CMPT340/Project/breastCancer/data/CMPT340_Project/dataset-classification/validation'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Set up Landing AI model\n",
    "deployed_model_endpoint = \"Your Endpoint ID\"  # Replace with your actual Landing AI model endpoint\n",
    "_api_key = \"Your API\"  # Replace with your actual Landing AI API key\n",
    "predictor = Predictor(endpoint_id=deployed_model_endpoint, api_key=_api_key)\n",
    "\n",
    "# Constants\n",
    "BENIGN = \"benign\"\n",
    "MALIGNANT = \"malignant\"\n",
    "NORMAL = \"normal\"\n",
    "\n",
    "def get_truth_label_from_name(filepath):\n",
    "    # Adjust this function to match your file naming conventions and classes\n",
    "    if 'benign' in filepath:\n",
    "        return BENIGN\n",
    "    elif 'malignant' in filepath:\n",
    "        return MALIGNANT\n",
    "    elif 'normal' in filepath:\n",
    "        return NORMAL\n",
    "    else:\n",
    "        raise Exception(\"Invalid filepath\")\n",
    "\n",
    "# Run inferences on Landing AI\n",
    "output_path = os.path.join(os.getcwd(), 'data/CMPT340_Project/dataset-classification', 'validation')   # Replace with the path to your validation set folder\n",
    "output_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a92c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: malignant\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: normal\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: benign\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: normal\tPrediction: normal\n",
      "Truth: normal\tPrediction: normal\n",
      "Truth: normal\tPrediction: normal\n",
      "Truth: normal\tPrediction: normal\n",
      "Truth: normal\tPrediction: normal\n",
      "Accuracy for BENIGN: 80.00%\n",
      "Accuracy for MALIGNANT: 93.33%\n",
      "Accuracy for NORMAL: 100.00%\n"
     ]
    }
   ],
   "source": [
    "test_images = sorted(glob.glob(os.path.join(output_path, '*.png')))\n",
    "frames = [Frame.from_image(im, metadata={\"truth\": get_truth_label_from_name(im)}) for im in test_images]\n",
    "\n",
    "correct_counts = {\n",
    "    BENIGN: 0,\n",
    "    MALIGNANT: 0,\n",
    "    NORMAL: 0,\n",
    "}\n",
    "\n",
    "for f in frames:\n",
    "    f.run_predict(predictor)\n",
    "    truth_label = f.metadata[\"truth\"]\n",
    "    # prediction = {score: float, label_name:str, label_index: int}\n",
    "    print(\"Truth: \" + truth_label + \"\\tPrediction: \" + f.predictions[0].label_name)\n",
    "    if f.predictions[0].label_name == truth_label:\n",
    "        correct_counts[truth_label] += 1\n",
    "    f.overlay_predictions()\n",
    "\n",
    "    \n",
    "print(\"Accuracy for BENIGN: %.2f%%\" % (correct_counts[BENIGN] / benign_validation_size*100))\n",
    "print(\"Accuracy for MALIGNANT: %.2f%%\" % (correct_counts[MALIGNANT] / malignant_validation_size*100))\n",
    "print(\"Accuracy for NORMAL: %.2f%%\" % (correct_counts[NORMAL] /normal_validation_size*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c780108",
   "metadata": {},
   "source": [
    "# Classification after Overlaying Mask images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f039407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set creation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the paths\n",
    "project_folder = os.path.join(os.getcwd(), 'data', 'CMPT340_Project')\n",
    "dataset_folder = os.path.join(project_folder, 'BreastCancerDataset')\n",
    "classification_overlayed_folder = os.path.join(project_folder, 'dataset-classification-overlayed')\n",
    "\n",
    "# Validation set sizes\n",
    "benign_validation_size = 10\n",
    "malignant_validation_size = 15\n",
    "normal_validation_size = 5\n",
    "\n",
    "# Function to overlay images and masks, resize if needed, and save the result\n",
    "def overlay_and_save(image_path, mask_path, output_folder, output_filename):\n",
    "    try:\n",
    "        # Check if both image and mask files exist\n",
    "        if os.path.exists(image_path) and os.path.exists(mask_path):\n",
    "            # Open the actual image and mask image\n",
    "            image = Image.open(image_path)\n",
    "            mask = Image.open(mask_path)\n",
    "\n",
    "            # Ensure both images have the same color mode\n",
    "            if image.mode != mask.mode:\n",
    "                mask = mask.convert(image.mode)\n",
    "\n",
    "            # Resize the images if their sizes don't match\n",
    "            if image.size != mask.size:\n",
    "                image = image.resize(mask.size)\n",
    "\n",
    "            # Overlay the image with the mask\n",
    "            overlayed = Image.blend(image, mask, alpha=0.5)\n",
    "\n",
    "            # Save the overlayed image\n",
    "            overlayed.save(os.path.join(output_folder, output_filename))\n",
    "        else:\n",
    "            # Print a message if files are not found\n",
    "            print(f\"File not found for: {image_path} or {mask_path}. Skipping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for: {image_path} or {mask_path}. Error: {str(e)}\")\n",
    "\n",
    "# Create the validation set folder\n",
    "validation_folder = os.path.join(classification_overlayed_folder, 'validation')\n",
    "\n",
    "# Remove the existing validation folder if it exists\n",
    "if os.path.exists(validation_folder):\n",
    "    shutil.rmtree(validation_folder)\n",
    "\n",
    "os.makedirs(validation_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through the subdirectories (benign, malignant, normal)\n",
    "for label in ['benign', 'malignant', 'normal']:\n",
    "    label_dir = os.path.join(dataset_folder, label)\n",
    "    if os.path.isdir(label_dir):\n",
    "        # Get the list of files in each class\n",
    "        files = [file for file in os.listdir(label_dir) if '_mask' not in file]\n",
    "        # Randomly select validation files\n",
    "        validation_files = random.sample(files, min(eval(f\"{label}_validation_size\"), len(files)))\n",
    "        for image_filename in validation_files:\n",
    "            image_path = os.path.join(label_dir, image_filename)\n",
    "            # Construct the mask file path based on the naming convention\n",
    "            mask_filename = image_filename.replace('.png', '_mask.png')\n",
    "            mask_path = os.path.join(label_dir, mask_filename)\n",
    "\n",
    "            # Overlay and save the image\n",
    "            overlay_and_save(image_path, mask_path, validation_folder, image_filename)\n",
    "\n",
    "# Print a message indicating that the validation set creation was successful\n",
    "print(\"Validation set creation completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea60b94",
   "metadata": {},
   "source": [
    "# Run inference on validation set of overlayed images with the trained model deployed from LandingAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c05d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sanyamsingh/Desktop/Courses/CMPT340/Project/data/CMPT340_Project/dataset-classification-overlayed/validation'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up Landing AI model\n",
    "deployed_model_endpoint = \"a9fe4fbd-671c-413c-837a-cee20cc79135\"  # Replace with your actual Landing AI model endpoint\n",
    "_api_key = \"land_sk_BBSVmLozWw0Pe1VVBVzWPwSsNSRESbPeKXNyaQNSnb9WzGwv8a\"  # Replace with your actual Landing AI API key\n",
    "predictor = Predictor(endpoint_id=deployed_model_endpoint, api_key=_api_key)\n",
    "\n",
    "# Constants\n",
    "BENIGN = \"benign\"\n",
    "MALIGNANT = \"malignant\"\n",
    "NORMAL = \"normal\"\n",
    "\n",
    "def get_truth_label_from_name(filepath):\n",
    "    # Adjust this function to match your file naming conventions and classes\n",
    "    if 'benign' in filepath:\n",
    "        return BENIGN\n",
    "    elif 'malignant' in filepath:\n",
    "        return MALIGNANT\n",
    "    elif 'normal' in filepath:\n",
    "        return NORMAL\n",
    "    else:\n",
    "        raise Exception(\"Invalid filepath\")\n",
    "\n",
    "# Run inferences on Landing AI\n",
    "output_path = os.path.join(os.getcwd(), 'data/CMPT340_Project/dataset-classification-overlayed', 'validation')   # Replace with the path to your validation set folder\n",
    "output_path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e4ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: benign\tPrediction: benign\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: benign\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: malignant\tPrediction: malignant\n",
      "Truth: normal\tPrediction: normal\n",
      "Truth: normal\tPrediction: normal\n",
      "Truth: normal\tPrediction: normal\n",
      "Truth: normal\tPrediction: normal\n",
      "Truth: normal\tPrediction: normal\n",
      "Accuracy for BENIGN: 100.00%\n",
      "Accuracy for MALIGNANT: 93.33%\n",
      "Accuracy for NORMAL: 100.00%\n"
     ]
    }
   ],
   "source": [
    "test_images = sorted(glob.glob(os.path.join(output_path, '*.png')))\n",
    "frames = [Frame.from_image(im, metadata={\"truth\": get_truth_label_from_name(im)}) for im in test_images]\n",
    "\n",
    "correct_counts = {\n",
    "    BENIGN: 0,\n",
    "    MALIGNANT: 0,\n",
    "    NORMAL: 0,\n",
    "}\n",
    "\n",
    "for f in frames:\n",
    "    f.run_predict(predictor)\n",
    "    truth_label = f.metadata[\"truth\"]\n",
    "    # prediction = {score: float, label_name:str, label_index: int}\n",
    "    print(\"Truth: \" + truth_label + \"\\tPrediction: \" + f.predictions[0].label_name)\n",
    "    if f.predictions[0].label_name == truth_label:\n",
    "        correct_counts[truth_label] += 1\n",
    "    f.overlay_predictions()\n",
    "\n",
    "    \n",
    "print(\"Accuracy for BENIGN: %.2f%%\" % (correct_counts[BENIGN] / benign_validation_size*100))\n",
    "print(\"Accuracy for MALIGNANT: %.2f%%\" % (correct_counts[MALIGNANT] / malignant_validation_size*100))\n",
    "print(\"Accuracy for NORMAL: %.2f%%\" % (correct_counts[NORMAL] /normal_validation_size*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55b75a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
